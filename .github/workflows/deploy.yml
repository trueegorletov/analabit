name: Deploy Analabit Backend

on:
  push:
    branches: [ master ]
  workflow_dispatch:

# Add permissions for the GitHub token
permissions:
  contents: read
  packages: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: analabit

jobs:
  # test:
  #   runs-on: ubuntu-latest
  #   continue-on-error: true  # Allow the workflow to continue even if tests fail
  #   steps:
  #   - uses: actions/checkout@v4
  #   
  #   - name: Set up Go
  #     uses: actions/setup-go@v4
  #     with:
  #       go-version: '1.21'
  #       cache: true
  #       
  #   - name: Install dependencies
  #     run: |
  #       sudo apt-get update
  #       sudo apt-get install -y poppler-utils
  #       
  #   - name: Run tests
  #     run: |
  #       # Verify pdftotext is available
  #       which pdftotext || (echo "pdftotext not found" && exit 1)
  #       go mod tidy
  #       go test -v ./...
  #     
  #   - name: Report test status
  #     if: always()
  #     run: |
  #       if [ ${{ job.status }} == 'success' ]; then
  #         echo "✅ All tests passed successfully"
  #       else
  #         echo "⚠️ Some tests failed, but the pipeline will continue."
  #         echo "Please review the test output and fix the issues when possible."
  #       fi

  build:
    # needs: test
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Increase timeout for builds
    outputs:
      api-tag: ${{ steps.meta-api.outputs.tags }}
      aggregator-tag: ${{ steps.meta-aggregator.outputs.tags }}
      producer-tag: ${{ steps.meta-producer.outputs.tags }}
      api-digest: ${{ steps.build-api.outputs.digest }}
      aggregator-digest: ${{ steps.build-aggregator.outputs.digest }}
      producer-digest: ${{ steps.build-producer.outputs.digest }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        driver-opts: |
          image=moby/buildkit:v0.12.0
      
    - name: Login to Container Registry
      id: login
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata for API
      id: meta-api
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.actor }}/analabit-api
        tags: |
          type=sha,prefix={{branch}}-
          
    - name: Extract metadata for Aggregator
      id: meta-aggregator
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.actor }}/analabit-aggregator
        tags: |
          type=sha,prefix={{branch}}-
          
    - name: Extract metadata for Producer
      id: meta-producer
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.actor }}/analabit-producer
        tags: |
          type=sha,prefix={{branch}}-
    
    - name: Build and push Producer
      id: build-producer
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./service/producer/Dockerfile
        push: true
        tags: ${{ steps.meta-producer.outputs.tags }}
        labels: ${{ steps.meta-producer.outputs.labels }}
        no-cache: true
        github-token: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push API
      id: build-api
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./service/api/Dockerfile
        push: true
        tags: ${{ steps.meta-api.outputs.tags }}
        labels: ${{ steps.meta-api.outputs.labels }}
        no-cache: true
        github-token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Build and push Aggregator
      id: build-aggregator
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./service/aggregator/Dockerfile
        push: true
        tags: ${{ steps.meta-aggregator.outputs.tags }}
        labels: ${{ steps.meta-aggregator.outputs.labels }}
        no-cache: true
        github-token: ${{ secrets.GITHUB_TOKEN }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    steps:
    - name: Deploy to production
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          set -e
          
          # Navigate to project directory
          cd /opt/analabit
          
          # Pull latest code
          echo "Pulling latest code from repository..."
          git fetch origin master
          git reset --hard origin/master
          
          # Check if .env file exists, if not, create it
          if [ ! -f ".env" ]; then
              echo "No .env file found. Generating a new one with secure credentials..."
              PG_PASS=$(openssl rand -base64 32)
              RABBIT_PASS=$(openssl rand -base64 32)
              MINIO_PASS=$(openssl rand -base64 32)
              ANALABIT_DB_PASS=$(openssl rand -base64 32)
              GRAFANA_PASS=$(openssl rand -base64 32 | tr -dc 'a-zA-Z0-9!@#$%^&*()_+?><:{}[]' | head -c 24)
              PROMETHEUS_PASS=$(openssl rand -base64 32 | tr -dc 'a-zA-Z0-9!@#$%^&*()_+?><:{}[]' | head -c 24)
              
              cat << EOT > .env
          # Production environment variables - Generated on $(date)
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=$PG_PASS
          POSTGRES_DB=postgres

          RABBITMQ_USER=analabit_rabbit
          RABBITMQ_PASSWORD=$RABBIT_PASS
          MINIO_ROOT_USER=analabit_minio
          MINIO_ROOT_PASSWORD=$MINIO_PASS

          # Analabit specific database
          ANALABIT_DB_NAME=analabit_db
          ANALABIT_DB_USER=analabit_user
          ANALABIT_DB_PASSWORD=$ANALABIT_DB_PASS

          # FlareSolverr configuration
          FLARESOLVERR_URL=http://flaresolverr:8191
          FLARESOLVERR_TIMEOUT_MS=60000

          # Monitoring credentials
          GRAFANA_USER=admin
          GRAFANA_PASSWORD=$GRAFANA_PASS
          PROMETHEUS_USER=prometheus
          PROMETHEUS_PASSWORD=$PROMETHEUS_PASS

          APP_ENV=production
          APP_PORT=8080
          LOG_LEVEL=info
          EOT
              echo ".env file created."
          else
              echo ".env file already exists. Skipping generation."
          fi
          
          # Check if Grafana and Prometheus credentials exist in .env, add if missing
          if ! grep -q "GRAFANA_USER" .env; then
              echo "Adding Grafana credentials to .env..."
              GRAFANA_PASS=$(openssl rand -base64 32 | tr -dc 'a-zA-Z0-9!@#$%^&*()_+?><:{}[]' | head -c 24)
              echo "" >> .env
              echo "# Monitoring credentials" >> .env
              echo "GRAFANA_USER=admin" >> .env
              echo "GRAFANA_PASSWORD=${GRAFANA_PASS}" >> .env
          fi
          
          if ! grep -q "PROMETHEUS_USER" .env; then
              echo "Adding Prometheus credentials to .env..."
              PROMETHEUS_PASS=$(openssl rand -base64 32 | tr -dc 'a-zA-Z0-9!@#$%^&*()_+?><:{}[]' | head -c 24)
              if ! grep -q "# Monitoring credentials" .env; then
                  echo "" >> .env
                  echo "# Monitoring credentials" >> .env
              fi
              echo "PROMETHEUS_USER=prometheus" >> .env
              echo "PROMETHEUS_PASSWORD=${PROMETHEUS_PASS}" >> .env
          fi
          
          # Append/update image tags in .env file
          sed -i '/_IMAGE=/d' .env
          cat << EOT >> .env
          
          # Image tags from CI build
          API_IMAGE=${{ needs.build.outputs.api-tag }}
          AGGREGATOR_IMAGE=${{ needs.build.outputs.aggregator-tag }}
          PRODUCER_IMAGE=${{ needs.build.outputs.producer-tag }}
          EOT
          
          # Login to container registry
          echo "Logging into GitHub Container Registry..."
          echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
          
          # Pull new images (including FlareSolverr automatically via compose file)
          echo "Pulling latest Docker images..."
          docker-compose -f docker-compose.prod.yml --env-file .env pull
          
          # Stop old containers and start new ones
          echo "Restarting services with new images and configuration..."
          docker-compose -f docker-compose.prod.yml --env-file .env up -d --force-recreate --remove-orphans
          
          # Health checks
          echo "Waiting for services to stabilize (10s)..."
          sleep 10
          
          echo "Waiting for FlareSolverr to be ready..."
          timeout 60 bash -c 'until docker exec $(docker-compose -f docker-compose.prod.yml ps -q flaresolverr) curl -sf http://localhost:8191/v1 >/dev/null 2>&1; do echo "Retrying FlareSolverr health check..."; sleep 5; done'
          
          echo "Waiting for API to be healthy..."
          timeout 60 bash -c 'until curl -sf http://localhost:8080/health; do echo "Retrying API health check..."; sleep 5; done'
          
          # Configure nginx for Prometheus and Grafana
          echo "Configuring nginx for monitoring endpoints..."
          
          # Get Prometheus credentials from .env
          PROM_USER=$(grep "PROMETHEUS_USER" .env | cut -d= -f2 || echo "prometheus")
          PROM_PASS=$(grep "PROMETHEUS_PASSWORD" .env | cut -d= -f2)
          
          # If no password found, generate one and add it to .env
          if [ -z "$PROM_PASS" ]; then
              PROM_PASS=$(openssl rand -base64 32 | tr -dc 'a-zA-Z0-9!@#$%^&*()_+?><:{}[]' | head -c 24)
              echo "PROMETHEUS_PASSWORD=$PROM_PASS" >> .env
          fi
          
          # Run the Nginx configuration script
          sudo /opt/analabit/scripts/update_nginx_monitoring.sh "$PROM_USER" "$PROM_PASS"
          
          # Clean up old images
          echo "Cleaning up old Docker images..."
          docker image prune -a -f --filter "until=24h"
          
          # Final status check
          echo "Final status check:"
          docker-compose -f docker-compose.prod.yml ps
          
          echo "✅ Deployment completed successfully!"
